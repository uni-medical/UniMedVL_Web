<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="UniMedVL: A unified medical foundation model enabling both understanding and generation capabilities within a single architecture">
  <meta name="keywords" content="UniMedVL, Medical AI, Vision-Language, Foundation Model, Medical Imaging, VQA">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="author" content="General Medical AI Research Team">
  <meta name="robots" content="index, follow">
  <title>UniMedVL: Unifying Medical Multimodal Understanding and Generation through Observation-Knowledge-Analysis</title>

  <!-- Canonical URL -->
  <link rel="canonical" href="https://uni-medical.github.io/UniMedVL/">

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://uni-medical.github.io/UniMedVL/">
  <meta property="og:title" content="UniMedVL: Unifying Medical Multimodal Understanding and Generation">
  <meta property="og:description" content="A unified medical foundation model enabling both understanding and generation capabilities within a single architecture">
  <meta property="og:image" content="https://uni-medical.github.io/UniMedVL/static/images/teaser.png">

  <!-- Twitter -->
  <meta property="twitter:card" content="summary_large_image">
  <meta property="twitter:url" content="https://uni-medical.github.io/UniMedVL/">
  <meta property="twitter:title" content="UniMedVL: Unifying Medical Multimodal Understanding and Generation">
  <meta property="twitter:description" content="A unified medical foundation model enabling both understanding and generation capabilities within a single architecture">
  <meta property="twitter:image" content="https://uni-medical.github.io/UniMedVL/static/images/teaser.png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" type="image/png" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="#overview">Overview</a>
      <a class="navbar-item" href="#methodology">Methodology</a>
      <a class="navbar-item" href="#results">Results</a>
    </div>
    <div class="navbar-end">
      <div class="navbar-item">
        <div class="buttons">
          <a href="index_zh.html" class="button is-light">
            <span class="icon">
              <i class="fas fa-language"></i>
            </span>
            <span>‰∏≠Êñá</span>
          </a>
        </div>
      </div>
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">UniMedVL: Unifying Medical Multimodal Understanding and Generation through Observation-Knowledge-Analysis</h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Junzhi Ning<sup>1*</sup>, Wei Li<sup>1,3*</sup>, Cheng Tang<sup>1,4*</sup>, Jiashi Lin<sup>1</sup>, Chenglong Ma<sup>2,5</sup>,<br>
              Chaoyang Zhang<sup>2</sup>, Jiyao Liu<sup>1,5</sup>, Ying Chen<sup>1</sup>, Shujian Gao<sup>1,5</sup>, Lihao Liu<sup>1</sup>,<br>
              Yuandong Pu<sup>1,3</sup>, Huihui Xu<sup>1,11</sup>, Chenhui Gou<sup>7</sup>, Ziyan Huang<sup>1</sup>, Yi Xin<sup>1,2</sup>,<br>
              Qi Qin<sup>1</sup>, Zhongying Deng<sup>6</sup>, Diping Song<sup>1</sup>, Bin Fu<sup>1</sup>, Guang Yang<sup>9</sup>,<br>
              Yuanfeng Ji<sup>10</sup>, Tianbin Li<sup>1</sup>, Yanzhou Su<sup>8</sup>, Jin Ye<sup>1,7</sup>, Shixiang Tang<sup>1</sup>, Ming Hu<sup>1,7</sup>,<br>
              Junjun He<sup>1,2‚Ä†</sup>
            </span>
          </div>

          <div class="is-size-6 publication-authors" style="margin-top: 1rem; line-height: 1.6;">
            <span class="author-block">
              <sup>1</sup>Shanghai Artificial Intelligence Laboratory,
              <sup>2</sup>Shanghai Innovation Institute,
              <sup>3</sup>Shanghai Jiao Tong University,<br>
              <sup>4</sup>Shanghai Institute of Optics and Fine Mechanics,
              <sup>5</sup>Fudan University,
              <sup>6</sup>University of Cambridge,
              <sup>7</sup>Monash University,<br>
              <sup>8</sup>Fuzhou University,
              <sup>9</sup>Imperial College London,
              <sup>10</sup>The University of Hong Kong,<br>
              <sup>11</sup>The Hong Kong University of Science and Technology
            </span>
          </div>

          <div class="is-size-7 publication-authors" style="margin-top: 0.5rem;">
            <span class="author-block">
              <sup>*</sup>Equal contribution. <sup>‚Ä†</sup>Corresponding author.
            </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Placeholder Links -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2510.15710" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/uni-medical/UniMedVL" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/General-Medical-AI/UniMedVL" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-cube"></i>
                  </span>
                  <span>Model</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser.png" alt="UniMedVL Overview" style="width: 100%; border-radius: 10px;" loading="lazy">
    </div>
  </div>
</section>

<!-- Abstract Section -->
<section class="section" style="background-color: #f8f9fa;">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">Abstract</h2>
        <div class="content has-text-justified" style="font-size: 1.05rem; line-height: 1.8;">
          <p>
            Clinical diagnosis demands models that can process multimodal medical inputs (images, patient histories, lab results) and generate diverse outputs including both textual reports and visual content (annotations, segmentation masks, and images). Despite this need, existing medical AI systems disrupt this unified process: medical image understanding models interpret images but cannot generate visual outputs, while medical image generation models synthesize images but cannot provide textual explanations. This leads to gaps in data representation, feature integration, and task-level multimodal capabilities.
          </p>
          <p>
            To this end, we propose a multi-level framework that mirrors clinical diagnosis through the <strong>Observation-Knowledge-Analysis (OKA) paradigm</strong>. Specifically, at the observation level, we construct UniMed-5M, a dataset comprising over <strong>5.6 million samples</strong> that reformat diverse unimodal data into multimodal pairs for foundational observation. At the knowledge level, we propose <strong>Progressive Curriculum Learning</strong> that systematically introduces medical multimodal knowledge. At the analysis level, we introduce <strong>UniMedVL</strong>‚Äîa medical unified multimodal model designed within the OKA paradigm for comprehensive analysis of image understanding and generation tasks <strong>within a single architecture</strong>.
          </p>
          <p>
            <strong>UniMedVL achieves superior performance on five medical image understanding benchmarks, while matching specialized models in generation quality across eight medical imaging modalities</strong>. Crucially, our unified architecture enables bidirectional knowledge sharing‚Äîgeneration tasks enhance visual understanding features, demonstrating that integrating traditionally separate capabilities within a single medical framework unlocks improvements across diverse clinical scenarios.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Overview Section -->
<section class="section" id="overview">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Core Innovation</h2>

        <!-- Clinical Scenario -->
        <div class="notification is-info is-light" style="text-align: left; margin: 2rem 0;">
          <h4 class="title is-5">üè• Clinical Diagnosis: A Multimodal Process</h4>
          <p style="margin-bottom: 1rem;">
            Consider a radiologist examining suspected lung pathology: they systematically process <strong>chest X-rays</strong> (visual), <strong>prior CT scans</strong> (cross-modal comparison), and <strong>patient history</strong> (textual) to generate multiple complementary outputs:
          </p>
          <ul style="margin-left: 2rem;">
            <li><strong>Detailed reports</strong> describing findings and reasoning</li>
            <li><strong>Visual annotations</strong> highlighting specific regions of concern</li>
            <li><strong>Comparative visualizations</strong> for treatment planning and surgical guidance</li>
          </ul>
          <p style="margin-top: 1rem;">
            This exemplifies how clinical diagnosis requires <strong>unified processing of multimodal inputs to generate diverse multimodal outputs</strong>, where neither textual reports alone (lacking spatial localization) nor visual annotations alone (lacking reasoning context) suffice.
          </p>
        </div>

        <!-- Problem Statement -->
        <div class="notification is-warning is-light" style="text-align: left; margin: 2rem 0;">
          <h4 class="title is-5">üî¥ Three-Level Fragmentation in Existing Medical AI</h4>
          <p style="margin-bottom: 1rem;">
            Despite multimodal fusion demonstrating substantial improvements in clinical decision-making, current medical AI remains fragmented at three critical levels:
          </p>

          <div style="margin-left: 1.5rem; margin-bottom: 1rem;">
            <p><strong>‚ë† Data Level:</strong> Medical datasets remain predominantly single-modal despite clear evidence that multimodal integration substantially improves diagnostic accuracy. Most datasets lack the paired multimodal structure needed for unified training.</p>
          </div>

          <div style="margin-left: 1.5rem; margin-bottom: 1rem;">
            <p><strong>‚ë° Feature Level:</strong> Current approaches lack systematic progressive training strategies for deep cross-modal relationships. Most methods simply concatenate features rather than progressively building from basic pattern recognition to sophisticated multimodal reasoning.</p>
          </div>

          <div style="margin-left: 1.5rem; margin-bottom: 1rem;">
            <p><strong>‚ë¢ Task Level:</strong> While general-domain models have made progress in unified architectures, the medical domain still lacks truly unified models. For instance, <strong>HealthGPT</strong> demonstrates both understanding and generation capabilities but requires <strong>reloading different model checkpoints</strong> to switch between task types‚Äîa limitation that prevents seamless multi-task operation in clinical workflows.</p>
          </div>

          <p style="margin-top: 1rem; padding: 0.75rem; background-color: #fff3cd; border-radius: 5px;">
            <strong>üìä Performance Gap:</strong> Current medical AI systems achieve less than <strong>60% accuracy</strong> compared to over <strong>90%</strong> for human experts on diagnostic challenges, highlighting the urgent need for unified approaches.
          </p>
        </div>

        <!-- Solution -->
        <div class="notification is-success is-light" style="text-align: left; margin: 2rem 0;">
          <h4 class="title is-5">‚úÖ UniMedVL: Unified Architecture for Medical Data across 8 Modalities</h4>
          <p>
            <strong>UniMedVL leverages the OKA framework to achieve comprehensive medical multimodal understanding and generation within a single model checkpoint.</strong> Once loaded, it seamlessly handles:
          </p>
          <ul>
            <li>üìñ <strong>Understanding Tasks</strong>: Medical VQA, image captioning, diagnostic report generation</li>
            <li>üé® <strong>Generation Tasks</strong>: Text-to-image synthesis, cross-modal translation (CT‚ÜîMRI), virtual staining</li>
            <li>üîÄ <strong>Interleaved Tasks</strong>: Counterfactual generation (simultaneous image + explanatory text), super-resolution, segmentation</li>
          </ul>
          <p style="margin-top: 1rem;">
            <strong>Key Advantage</strong>: No offline checkpoint switching‚Äîsingle model completes all tasks ‚ú®
          </p>
        </div>

        <!-- Key Numbers -->
        <div class="content has-text-justified">
          <h3 class="title is-4 has-text-centered" style="margin-top: 2rem;">Key Statistics</h3>
          <div class="columns" style="margin-top: 1.5rem;">
            <div class="column">
              <div class="box" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; text-align: center;">
                <p class="title is-2" style="color: white; margin-bottom: 0.5rem;">5.6M+</p>
                <p class="subtitle is-5" style="color: white;">Training Samples</p>
                <p style="font-size: 0.9rem;">9 medical imaging modalities</p>
              </div>
            </div>
            <div class="column">
              <div class="box" style="background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%); color: white; text-align: center;">
                <p class="title is-2" style="color: white; margin-bottom: 0.5rem;">96.29</p>
                <p class="subtitle is-5" style="color: white;">Average gFID</p>
                <p style="font-size: 0.9rem;">Matching specialized generation models</p>
              </div>
            </div>
          </div>
        </div>

      </div>
    </div>
  </div>
</section>

<!-- Methodology Section -->
<section class="section" id="methodology">
  <div class="container is-max-desktop">

    <!-- OKA Framework -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">OKA Framework: Observation-Knowledge-Analysis</h2>
        <div class="content has-text-justified">
          <p>
            UniMedVL follows a clinical workflow-guided three-level framework that mirrors how physicians process medical information:
          </p>
        </div>

        <div class="content has-text-left" style="max-width: 800px; margin: 2rem auto;">
          <ol>
            <li><strong>Observation Level (Data)</strong>: Construct UniMed-5M dataset with quality control and expert validation</li>
            <li><strong>Knowledge Level (Features)</strong>: Progressive curriculum learning and cross-modal knowledge fusion</li>
            <li><strong>Analysis Level (Tasks)</strong>: Unified architecture producing multimodal outputs (reports, images, annotations)</li>
          </ol>
        </div>
      </div>
    </div>

    <hr style="margin: 3rem 0;">

    <!-- Architecture -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Data Pipeline and Model Architecture</h2>
        <img src="./static/images/overview_ver3.png" alt="Architecture Overview" style="width: 100%; border-radius: 10px;" loading="lazy">
        <p style="margin-top: 1rem;"><em>Comprehensive data processing pipeline and model architecture overview</em></p>
      </div>
    </div>

    <hr style="margin: 3rem 0;">

    <!-- Training Strategy -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Progressive Training Strategy</h2>
        <div class="content has-text-justified">
          <p><strong>Three-Stage Progressive Curriculum Learning:</strong></p>

          <div class="columns">
            <div class="column">
              <h4>üîß Stage 1 - Foundation Training</h4>
              <ul>
                <li>85K training steps</li>
                <li>Basic medical pattern recognition</li>
                <li>Visual-language alignment</li>
                <li>Data ratio: 75% I2T, 25% T2I</li>
              </ul>
            </div>

            <div class="column">
              <h4>üìö Stage 2 - Instruction Tuning</h4>
              <ul>
                <li>120K training steps</li>
                <li>Cross-modal understanding enhancement</li>
                <li>Medical expertise development</li>
                <li>Data ratio: 40% I2T, 45% T2I, 10% Interleaved</li>
              </ul>
            </div>

            <div class="column">
              <h4>üöÄ Stage 3 - Unified Training</h4>
              <ul>
                <li>70K training steps</li>
                <li>Advanced multimodal synthesis</li>
                <li>Interleaved task mastery</li>
                <li>Data ratio: 37% I2T, 35% T2I, 25% Interleaved</li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>

  </div>
</section>

<!-- Performance Highlights Section -->
<section class="section" style="background-color: #f8f9fa;">
  <div class="container is-max-desktop">
    <h2 class="title is-2 has-text-centered">Performance Highlights</h2>
    <p class="subtitle has-text-centered" style="margin-bottom: 3rem;">
      Single model, comprehensive coverage of understanding, generation, and interleaved tasks
    </p>

    <!-- Understanding Performance -->
    <div style="margin: 3rem 0;">
      <h3 class="title is-3 has-text-centered" style="color: #667eea;">üìñ Medical Image Understanding</h3>
      <div class="columns is-multiline">
        <div class="column is-one-third">
          <div class="box" style="border-left: 4px solid #667eea;">
            <p class="heading">PathVQA</p>
            <p class="title is-3">53.5%</p>
            <p class="subtitle is-6">vs. HealthGPT-L14 44.4%</p>
          </div>
        </div>
        <div class="column is-one-third">
          <div class="box" style="border-left: 4px solid #667eea;">
            <p class="heading">OmniMedVQA</p>
            <p class="title is-3">85.8%</p>
            <p class="subtitle is-6">vs. GMAI-VL 88.5%</p>
          </div>
        </div>
        <div class="column is-one-third">
          <div class="box" style="border-left: 4px solid #667eea;">
            <p class="heading">VQA-RAD</p>
            <p class="title is-3">61.9%</p>
            <p class="subtitle is-6">vs. GMAI-VL 66.3%</p>
          </div>
        </div>
        <div class="column is-one-third">
          <div class="box" style="border-left: 4px solid #667eea;">
            <p class="heading">GMAI-MMBench</p>
            <p class="title is-3">60.75%</p>
            <p class="subtitle is-6">Comprehensive medical multimodal benchmark</p>
          </div>
        </div>
      </div>
    </div>

    <!-- Generation Performance -->
    <div style="margin: 3rem 0;">
      <h3 class="title is-3 has-text-centered" style="color: #f5576c;">üé® Medical Image Generation</h3>
      <div class="columns is-multiline">
        <div class="column is-one-quarter">
          <div class="box" style="border-left: 4px solid #f5576c;">
            <p class="heading">Chest X-ray (CXR)</p>
            <p class="title is-4">73.04</p>
            <p class="subtitle is-6">gFID</p>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="box" style="border-left: 4px solid #f5576c;">
            <p class="heading">Histopathology (HIS)</p>
            <p class="title is-4">149.01</p>
            <p class="subtitle is-6">gFID</p>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="box" style="border-left: 4px solid #f5576c;">
            <p class="heading">Fundus Photo (CFP)</p>
            <p class="title is-4">53.20</p>
            <p class="subtitle is-6">gFID</p>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="box" style="border-left: 4px solid #f5576c;">
            <p class="heading">CT Scan</p>
            <p class="title is-4">73.04</p>
            <p class="subtitle is-6">gFID</p>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="box" style="border-left: 4px solid #f5576c;">
            <p class="heading">MRI</p>
            <p class="title is-4">90.36</p>
            <p class="subtitle is-6">gFID</p>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="box" style="border-left: 4px solid #f5576c;">
            <p class="heading">OCT</p>
            <p class="title is-4">99.27</p>
            <p class="subtitle is-6">gFID</p>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="box" style="border-left: 4px solid #f5576c;">
            <p class="heading">Ultrasound</p>
            <p class="title is-4">95.38</p>
            <p class="subtitle is-6">gFID</p>
          </div>
        </div>
        <div class="column is-one-quarter">
          <div class="box" style="border-left: 4px solid #f5576c;">
            <p class="heading">Endoscopy</p>
            <p class="title is-4">133.11</p>
            <p class="subtitle is-6">gFID</p>
          </div>
        </div>
      </div>
      <p class="has-text-centered" style="margin-top: 1rem;">
        <span class="tag is-success is-medium">Average gFID: 96.29</span>
        <span class="tag is-info is-medium" style="margin-left: 1rem;">BioMedCLIP: 0.706</span>
      </p>
    </div>

    <!-- Interleaved Tasks Performance -->
    <div style="margin: 3rem 0;">
      <h3 class="title is-3 has-text-centered" style="color: #00f2fe;">üîÄ Interleaved Tasks (Understanding + Generation)</h3>
      <div class="columns">
        <div class="column">
          <div class="box" style="border-left: 4px solid #00f2fe;">
            <p class="heading">Virtual Immunohistochemistry Staining</p>
            <p class="title is-3">20.27 / 0.456</p>
            <p class="subtitle is-6">PSNR / SSIM</p>
          </div>
        </div>
        <div class="column">
          <div class="box" style="border-left: 4px solid #00f2fe;">
            <p class="heading">MRI Super-Resolution (4√ó)</p>
            <p class="title is-3">27.29 / 0.890</p>
            <p class="subtitle is-6">PSNR / SSIM</p>
          </div>
        </div>
        <div class="column">
          <div class="box" style="border-left: 4px solid #00f2fe;">
            <p class="heading">Cross-Modal Synthesis (T2‚ÜîFLAIR)</p>
            <p class="title is-3">25.07 / 0.882</p>
            <p class="subtitle is-6">Average PSNR / SSIM</p>
          </div>
        </div>
      </div>
      <div class="columns">
        <div class="column is-half is-offset-one-quarter">
          <div class="box" style="border-left: 4px solid #00f2fe; background-color: #e8f9ff;">
            <p class="heading">Counterfactual Generation (Image + Text Explanation)</p>
            <p class="title is-4">gFID: 27.17 | AUROC: 0.797</p>
            <p class="subtitle is-6">BLEU-3: 0.2641 | METEOR: 0.4486 | ROUGE-L: 0.4649</p>
          </div>
        </div>
      </div>
    </div>

    <!-- Unified Architecture Advantage -->
    <div class="notification is-primary is-light" style="margin-top: 3rem;">
      <h4 class="title is-4 has-text-centered">üåü Clinical Advantages of Unified Architecture</h4>
      <div class="columns">
        <div class="column">
          <p style="text-align: center;">
            <span class="icon is-large" style="color: #3273dc;"><i class="fas fa-check-circle fa-2x"></i></span>
          </p>
          <p style="text-align: center; font-weight: bold;">Seamless Task Switching</p>
          <p style="text-align: center; font-size: 0.9rem;">Complete all tasks<br>without switching checkpoints</p>
        </div>
        <div class="column">
          <p style="text-align: center;">
            <span class="icon is-large" style="color: #3273dc;"><i class="fas fa-sync-alt fa-2x"></i></span>
          </p>
          <p style="text-align: center; font-weight: bold;">Bidirectional Knowledge Sharing</p>
          <p style="text-align: center; font-size: 0.9rem;">Generation tasks enhance understanding<br>Understanding tasks optimize generation</p>
        </div>
        <div class="column">
          <p style="text-align: center;">
            <span class="icon is-large" style="color: #3273dc;"><i class="fas fa-hospital fa-2x"></i></span>
          </p>
          <p style="text-align: center; font-weight: bold;">Clinical Workflow Integration</p>
          <p style="text-align: center; font-size: 0.9rem;">Aligning with clinical practice<br>Observation-Knowledge-Analysis workflow</p>
        </div>
      </div>
    </div>

  </div>
</section>

<!-- Results Section -->
<section class="section" id="results">
  <div class="container is-max-desktop">
    <h2 class="title is-2 has-text-centered">Experimental Results Visualization</h2>

    <!-- Performance Comparison -->
    <div style="margin: 3rem 0;">
      <h3 class="title is-3 has-text-centered">Performance Visualization Comparison</h3>
      <img src="./static/images/topline_performance.png" alt="Performance Comparison" style="width: 100%; border-radius: 10px;" loading="lazy">
      <p class="has-text-centered" style="margin-top: 1rem;"><em>Comprehensive performance comparison across different training stages and modalities</em></p>
    </div>

    <!-- Multimodal Tasks -->
    <div style="margin: 3rem 0;">
      <h3 class="title is-3 has-text-centered">Multimodal Task Demonstrations</h3>
      <img src="./static/images/fig_results_ver2.png" alt="Multimodal Results" style="width: 100%; border-radius: 10px;" loading="lazy">
      <p class="has-text-centered" style="margin-top: 1rem;"><em>Comprehensive visualization of UniMedVL's multimodal capabilities</em></p>
    </div>

    <!-- VQA and Report Generation -->
    <div style="margin: 3rem 0;">
      <div style="margin-bottom: 3rem;">
        <h3 class="title is-4">üí¨ Medical Visual Question Answering</h3>
        <img src="./static/images/visual_question_answering.png?v=2" alt="VQA Examples" style="width: 100%; border-radius: 10px;" loading="lazy">
        <p class="has-text-centered" style="margin-top: 0.5rem; color: #667eea; font-weight: bold;">Accuracy: SLAKE 75.4% | PathVQA 53.5%</p>
      </div>
      <div>
        <h3 class="title is-4">üìÑ Medical Report Generation</h3>
        <img src="./static/images/reportgeneration.png?v=2" alt="Report Generation" style="width: 100%; border-radius: 10px;" loading="lazy">
        <p class="has-text-centered" style="margin-top: 0.5rem; color: #667eea; font-weight: bold;">Generating detailed medical diagnostic reports</p>
      </div>
    </div>

    <!-- Text-to-Image -->
    <div style="margin: 3rem 0;">
      <h3 class="title is-3 has-text-centered">üé® Text-Driven Medical Image Generation</h3>
      <div style="margin-bottom: 2rem;">
        <img src="./static/images/text2img1.png?v=2" alt="T2I Example 1" style="width: 100%; border-radius: 10px;" loading="lazy">
      </div>
      <div style="margin-bottom: 2rem;">
        <img src="./static/images/text2img2.png?v=2" alt="T2I Example 2" style="width: 100%; border-radius: 10px;" loading="lazy">
      </div>
      <p class="has-text-centered" style="margin-top: 1rem;">
        <em>High-quality text-driven image generation across 8 medical imaging modalities</em>
        <br>
        <span class="tag is-success is-medium" style="margin-top: 0.5rem;">Average gFID: 96.29 | BioMedCLIP: 0.706</span>
      </p>
    </div>

    <!-- VAE Reconstruction -->
    <div style="margin: 3rem 0;">
      <h3 class="title is-3 has-text-centered">üî¨ VAE Reconstruction Quality</h3>
      <img src="./static/images/vae_demo_ver1.png" alt="VAE Reconstruction" style="width: 100%; border-radius: 10px;" loading="lazy">
      <p class="has-text-centered" style="margin-top: 1rem;"><em>Qualitative comparison across diverse medical imaging modalities</em></p>
    </div>

    <!-- Medical Imaging Modalities Gallery -->
    <div style="margin: 3rem 0;">
      <h3 class="title is-3 has-text-centered">üî¨ Medical Imaging Modalities</h3>
      <p class="subtitle has-text-centered" style="margin-bottom: 2rem;">
        Eight different medical imaging modalities supported by UniMedVL
      </p>

      <div style="margin-top: 2rem;">
        <div style="text-align: center; margin-bottom: 2rem;">
          <img src="./static/images/cxr.png" alt="Chest X-ray" style="width: 100%; border-radius: 10px;" loading="lazy">
          <p class="has-text-centered" style="margin-top: 0.5rem; font-weight: bold;">Chest X-ray (CXR)</p>
        </div>
        <div style="text-align: center; margin-bottom: 2rem;">
          <img src="./static/images/ct.png" alt="CT Scan" style="width: 100%; border-radius: 10px;" loading="lazy">
          <p class="has-text-centered" style="margin-top: 0.5rem; font-weight: bold;">CT Scan</p>
        </div>
        <div style="text-align: center; margin-bottom: 2rem;">
          <img src="./static/images/mri.png" alt="MRI" style="width: 100%; border-radius: 10px;" loading="lazy">
          <p class="has-text-centered" style="margin-top: 0.5rem; font-weight: bold;">MRI</p>
        </div>
        <div style="text-align: center; margin-bottom: 2rem;">
          <img src="./static/images/ultrasound.png" alt="Ultrasound" style="width: 100%; border-radius: 10px;" loading="lazy">
          <p class="has-text-centered" style="margin-top: 0.5rem; font-weight: bold;">Ultrasound</p>
        </div>
        <div style="text-align: center; margin-bottom: 2rem;">
          <img src="./static/images/oct.png" alt="OCT" style="width: 100%; border-radius: 10px;" loading="lazy">
          <p class="has-text-centered" style="margin-top: 0.5rem; font-weight: bold;">OCT (Optical Coherence Tomography)</p>
        </div>
        <div style="text-align: center; margin-bottom: 2rem;">
          <img src="./static/images/retinal.png" alt="Retinal Fundus" style="width: 100%; border-radius: 10px;" loading="lazy">
          <p class="has-text-centered" style="margin-top: 0.5rem; font-weight: bold;">Retinal Fundus Photo</p>
        </div>
        <div style="text-align: center; margin-bottom: 2rem;">
          <img src="./static/images/his.png" alt="Histopathology" style="width: 100%; border-radius: 10px;" loading="lazy">
          <p class="has-text-centered" style="margin-top: 0.5rem; font-weight: bold;">Histopathology (HIS)</p>
        </div>
        <div style="text-align: center; margin-bottom: 2rem;">
          <img src="./static/images/endoscopy.png" alt="Endoscopy" style="width: 100%; border-radius: 10px;" loading="lazy">
          <p class="has-text-centered" style="margin-top: 0.5rem; font-weight: bold;">Endoscopy</p>
        </div>
      </div>
    </div>

  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <!-- Acknowledgments -->
          <h3 class="title is-4 has-text-centered">üôè Acknowledgments</h3>
          <p class="has-text-centered">
            We sincerely thank the following projects for their invaluable open-source contributions:
            <a href="https://github.com/ByteDance-Seed/Bagel">Bagel</a>,
            <a href="https://github.com/DCDmllm/HealthGPT">HealthGPT</a>,
            <a href="https://github.com/End2End-Diffusion/REPA-E">REPA-E</a>, and
            <a href="https://github.com/open-compass/VLMEvalKit">VLMEvalKit</a>.
          </p>

          <hr style="margin: 2rem 0;">

          <!-- License and Template Credit -->
          <p class="has-text-centered">
            This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p class="has-text-centered">
            Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            Thank you for the excellent design!
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
